# ConvoBuddy

**ConvoBuddy** is a local AI-powered chatbot built using **Node.js**, leveraging the power of an **Ollama** instance running directly on your device. Designed for smooth, intelligent conversations, ConvoBuddy provides a secure, responsive, and user-friendly chat experience, making it the perfect virtual companion for any occasion.

## Features

- **Default Connection to Ollama**: ConvoBuddy is pre-configured to connect to a local Ollama instance, ensuring fast, reliable, and secure AI interactions without relying on external servers.
  
- **Easy Switching Between Models**: Seamlessly switch between different models with just a few clicks, offering flexibility and customization for a wide range of use casesâ€”from casual conversations to problem-solving.

- **Proper Chat Flow**: Enjoy an intuitive and organized chat interface, where conversations are displayed cleanly and responses are natural. The app ensures a smooth flow of interactions, making it easy to pick up where you left off.

- **Local Data Processing**: With all data processed locally, ConvoBuddy prioritizes your privacy, keeping all conversations and information securely on your device.

- **Real-Time AI Responses**: Experience fast, real-time interactions powered by a local Ollama instance, allowing you to have immediate, intelligent conversations whenever you need them.

- **User-Friendly Interface**: ConvoBuddy features a sleek, easy-to-navigate design built with **Electron** and **Node.js**, making chatting with your AI companion a delightful experience, whether for work or play.

## Installation

To get started with ConvoBuddy, you have two options:

### 1. **Build the app from source**

#### Prerequisites
Before you start, make sure you have the following installed:

- **Node.js**: [Installation Guide](https://nodejs.org/en/download/)
- **Ollama**: [Installation Guide](https://ollama.com/)

#### Setup Steps

1. **Clone the repository**:
    ```bash
    git clone https://github.com/vishruthp/convobuddy.git
    cd convobuddy
    ```

2. **Install dependencies**:
    ```bash
    npm install
    ```

3. **Set up Ollama**:
   - Ensure that you have an Ollama instance running locally on your machine. If you haven't set it up yet, follow the [Ollama installation guide](https://ollama.com/).
   
4. **Run the app**:
    ```bash
    npm run dev
    ```

5. Open your app, and you can start chatting with ConvoBuddy!

---

### 2. **Download the latest release**

You can also download the latest release of ConvoBuddy from the **[Releases](https://github.com/vishruthp/convobuddy/releases)** page.

1. Go to the **[Releases page](https://github.com/vishruthp/convobuddy/releases)**.
2. Download the latest version for your operating system (Windows, macOS, or Linux).
3. Extract the downloaded file to a folder of your choice.
4. Run the executable to start using ConvoBuddy!

## Switching Models

ConvoBuddy comes with the ability to easily switch between different AI models powered by Ollama. To change models:

1. Go to the **Settings** tab within the app.
2. Choose from a list of available models.
3. Your selection will be applied immediately, and you can resume chatting with the new model.

## Privacy

ConvoBuddy processes all chat data locally, ensuring that no personal information leaves your device. We value your privacy and have built ConvoBuddy with security in mind.

## Contributing

We welcome contributions! If you'd like to contribute to the development of ConvoBuddy, feel free to fork the repository, make your changes, and submit a pull request.

### Steps for contributing:

1. Fork the repo.
2. Create a feature branch.
3. Make your changes.
4. Commit your changes with descriptive messages.
5. Push to your forked repo and create a pull request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
               